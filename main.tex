\documentclass[conference]{IEEEtran}
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage[inline]{enumitem}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Research directions for Aggregate Computing with Machine Learning}

\author{\IEEEauthorblockN{PhD Student Gianluca Aguzzi}
\IEEEauthorblockA{\textit{Alma Mater Studiorum - Università di Bologna} \\
Cesena, Italy \\
gianluca.aguzzi@unibo.it}
% \and
% \IEEEauthorblockN{Supervisor Mirko Viroli}
% \IEEEauthorblockA{\textit{Alma Mater Studiorum - Università di Bologna} \\
% Cesena, Italy \\
% mirko.viroli@unibo.it}
}

\maketitle
\begin{abstract}
    Collective adaptive systems (CASs) are challenging from the engineering perspective. 
%
    Different techniques aim at taming these systems, either using declarative or black-box approaches (e.g. Machine Learning, Evolutionary Algorithms, etc.).
%
    Among the many declarative approaches, Aggregate Computing is a novel technique by which developers can express collective system behaviours from a global perspective, using a compositional and functional programming technique.
%
    Over the years, Aggregate Computing has been applied in different scenarios, ranging from smart cities to crowd of augmented people. 
%
    Despite its promising capabilities, it is sometimes challenging to describe aggregate behaviours, so we aim at merging Aggregate Computing with black-box techniques to simplify the aggregate program synthesis.
\end{abstract}
\begin{IEEEkeywords}
Field Coordination, Aggregate Computing, Machine Learning, Multi-Agent Reinforcement Learning
\end{IEEEkeywords}

\section{Motivation and challenges}
Humans, in the last century, have filled the Earth with computational entities. 
%
%We find things able to compute in smartphones, fridges, and watches. % improve this period
%
Nowadays, these devices are not isolated; rather, they form a hoard of inter-communicating entities capable of achieving collective tasks.
% 
TThese systems exhibit characteristics normally seen in complex systems, such as large-scale, decentralised control and the emergence of global behaviour from local interactions~\cite{DBLP:conf/huc/Ferscha15}.
% 
Swarm of UAVs, a crowd of people, and smart cities are all instances of this kind of system, usually called Collective Adaptive Systems (CASs).

In literature, different techniques aim at managing this complexity at the engineering level.
%
Among the many, a solution that uses a top-down approach in expressing global behaviours is Aggregate Computing (AC)~\cite{DBLP:journals/computer/BealPV15}, classified under the umbrella of Field-Based Coordination~\cite{DBLP:books/daglib/0015276}).
%
AC represents a novel approach in which developers can express the collective behaviour declaratively by a functional manipulation of a distributed data structure called \emph{computational field}.

AC is backed by field calculus, a minimal set of constructs necessary to express whatever spatiotemporal computation through the manipulation of computational fields~\cite{DBLP:conf/coordination/AudritoBDV18}. 
%
On top of that, different building blocks have been built to facilitate high-level libraries definition.
%
Furthermore, crafting a specific blocks category, it is possible to verify relevant properties such as self-stabilisation~\cite{DBLP:conf/coordination/ViroliD14} and eventual consistency~\cite{DBLP:conf/saso/BealVPD16}.
%
Practically though, building these blocks is not straightforward as it may appear . 
%
Moreover, it is challenging to guarantee certain quality levels under different network conditions (e.g., different topologies, high node mobility, etc.)

Outward of top-down and declarative approaches, in the context of Collective Self-Adaptive System (CSAS)~\cite{DBLP:conf/metacognition/Mitchell05} (i.e. CAS where agents might have learning capabilities), other solutions leverage Evolutionary Computing~\cite{DBLP:journals/swarm/BrambillaFBD13} and Machine Learning (ML) to design multi-agents programs. 
%
In ML applications, Reinforcement Learning (RL)~\cite{DBLP:journals/access/NaeemRC20} and Multi-Agent RL~\cite{DBLP:journals/tcyb/NguyenNN20}) are typically  used.
%
Exploiting these techniques leads to near-optimal solutions for specific and complex applications such as multiplayer games~\cite{DBLP:journals/nature/VinyalsBCMDCCPE19, DBLP:journals/taas/HaoLM15}, traffic control~\cite{DBLP:journals/aes/JinMK17, DBLP:conf/icac/SteinTRH16} and robotics~\cite{DBLP:journals/taas/KraemerB14}.
%
Unfortunately, though, there are many problems to overcome with those solutions, for instance,
\begin{enumerate*}[label=(\roman*)]
    \item the transferability of the synthesised behaviours in other environments, 
    \item it is still a handcrafted process heavily influenced by the domain expertise, and
    \item their black-box nature.
\end{enumerate*}

Definitely, the AC model is challenging in terms of common learning problems. Indeed:
\begin{enumerate*}[label=(\roman*)]
\item there is no population size guarantee,
\item the node neighbourhood is potentially highly dynamic,
\item the system behaviour is usually evaluated at the macro-level and not at the micro-level, and
\item each node has partial information about the system (in typical Dec-POMDP~\cite{DBLP:conf/uai/BernsteinZI00} settings).
\end{enumerate*}
Moreover, the framework described in~\cite{DAngelo2019} allows to classify AC in terms of limited neighbourhood knowledge, restricted autonomy (i.e. agents execute a program shared by another agent), and altruistic behaviour (i.e. they act trying to achieve the correct global state).
\section{Contribution and objectives}
AC (and Field Coordination) has never been integrated with ML capabilities.
%
Therefore our intuition is to set up our work towards this integration.
%
As contribution, this combination adds online adaptability to a composable, self-explanatory language and makes aggregate programs more robust to environmental changes.
%
This intuition has inevitably led to the following questions that guided us in the preliminary research phases: 
at what level of abstraction (middleware? Application API? Building blocks?) learning can be useful for AC?
%
In state-of-the-art related techniques, how can they handle these non-deterministic and complex systems?
%
What are the common properties that AC has w.r.t other solutions?
\section{Methodology and preliminary results}
%
As the first step, we consider related work in Multi-Agent Systems, CSAS, and Swarm Robotics because they have similar settings to our model.
To reach our objective, we iteratively 
\begin{enumerate*}[label=(\roman*)]
\item read works at the state-of-the-art,
\item take inspiration from one of them to craft an initial prototype, and then
\item try to generalise the solution to solve more complex (in terms of Glass' law~\cite{DBLP:journals/software/Glass01}) problems.
\end{enumerate*}

AC is currently supported by different toolkits as ScaFi~\cite{DBLP:conf/ecoop/CasadeiV16} and Protelis~\cite{DBLP:conf/sac/PianiniVB15}, giving us fast prototype capabilities.
%
In our workflow, we evaluate our results leveraging simulations because of the cost of setting up a large scale system.
%
In the AC literature, the Alchemist~\cite{alchemist-jos2013} simulator is often chosen thanks to its adaptability of different application kinds, ranging from augmented crowds to smart cities.

Initially, we tried to improve our state-of-the-art handcrafted algorithms by evaluating them against our ML synthesised solution.
%
The criteria used to evaluate a solution are:
\begin{itemize}
    \item Correctness: does the solution reach, at some point in time, the right value?
    \item Stabilisation time: how much time need the solution to reach a stable state?
    \item Robustness in network topologies: is the solution robust against network changes (failure, node movement)?
\end{itemize}

Currently, we have applied ML at the building blocks level.
The reasons are:
\begin{enumerate*}[label=(\roman*)]
\item building blocks impact on the robustness/adaptivity of applications,
\item it is easy to know/simulate the desired state of the system, and
\item there is no robust implementation for some of them overcoming the problem of structural changes in the network.
\end{enumerate*}
%
At this level, the collective behaviour is homogeneous and collaborative and so, all agents execute the same program to achieve a common goal.
%
For this reason, we can frame the learning model as a Homogeneous Team Learning~\cite{DBLP:journals/aamas/PanaitL05}, i.e., it is possible to learn a good strategy centrally (with a single agent) and then distribute it evenly across the aggregate.
%
To simplify the problem, we also decided to apply ML at design time (offline, before the application is deployed).

Our test application is the distance gradient from a source zone. %% TODO improve here.
%
It is a pattern used to establish relevant collective behaviours (cf. distributed sensing).
%
Naive gradient implementations suffer from slow-rising, so different handcrafted solutions have been built, such as Flex, BIS, and ULT~\cite{DBLP:conf/saso/AudritoCDV17}.
%
Our goal is to reach a similar, or even better, performance of the best handmade solution (the ULT gradient).

At the moment of writing, none of the following novel methods brings us to good results. They are investigations that will hopefully yield results in the future and currently led us to understand limitations and opportunities.

From related works~\cite{DAngelo2019}, we observe a current trend in applying standard RL algorithms in CAS -- In particular, in CSAS.
%
As a first attempt, we tried to encode our gradient problem as an RL problem and then use Q-Learning~\cite{DBLP:journals/ras/Krose95}, (or Monte Carlo Learning~\cite{DBLP:conf/nips/Thrun99}) to solve it.
%
These experiments have shed light on some difficulties, which are: encoding local state indicating the values of the neighbours, finding a proper reward function expressing the individual utility in terms of the collective outcome and, encode right actions. 

Then we also considered setting up learning as a regression problem so that we can use Supervised Learning.
% 
Although it is a promising idea, this method does not currently scale to complex problems.
%
Even with a global system observation, it is tedious to know the correct outcome at a given time, so we cannot specify the ground truth for our learning algorithms.
%
Finally, observing evolutionary robotics, we try some basic evolutionary algorithms, such as NEAT~\cite{DBLP:journals/ec/StanleyM02}.
%
The advantages are the limited constraints that are imposed. Indeed, the encoding is straightforward, and the fitness function is easier to define than the reward function.
%
The problems encountered with this approach are the slowness and the difficulty in generalisation.
%
\section{Future work and research plan}
One of the problems encountered is the difficulty of encoding the state space in a fixed and dense dimension. 
%
In the literature, these problems are referred to as \emph{node embedding}. 
%
Novel works use Graph Neural Network (GNN)~\cite{DBLP:journals/tnn/ScarselliGTHM09} to learn the proper embedding.
%
Even if the configuration is quite different from our model, we can draw inspiration from them to possibly improve our learning model as done in~\cite{DBLP:conf/nips/SukhbaatarSF16}.

Deep RL has gained interest in recent years, thanks to the famous work of Atari games~\cite{DBLP:journals/corr/HosuR16}. 
%
Recent works~\cite{DBLP:journals/aamas/Hernandez-LealK19} investigate the application of deep neural networks model in Multi-Agents context to solve well-known problems (non-stationary, partial observability, large state space, etc.). 
%
At present, we do not use these techniques because of the simple nature of the building blocks. However, if we want to apply learning processes with more advanced building blocks (cf. leader election), these techniques might be necessary.

Beyond building blocks learning, AC needs a platform upon which execute programs. 
%
Here, designers need to define aspects that the paradigm does not include, such as evaluation frequency, program displacement, and trust.
% 
These themes are partially tackled in different works~\cite{DBLP:journals/scp/CasadeiAV18, DBLP:journals/fi/CasadeiPPVW20, DBLP:journals/corr/abs-2012-13806}, but online learning is usually not considered since it would improve the system robustness.

%In conclusion, we try to define my PhD research path to accomplish our goal (AC and ML integration).
%
%The main steps are:
%
In conclusion, a possible PhD research path that accomplishes our goal (AC and ML integration) is:
\begin{itemize}
    \item 1st year: continue the investigation to choose a good ML model -- always at design time -- while maintaining the gradient as a workbench.
    \item 2nd year: extend the work to other blocks of aggregate programming (e.g. distributed leader election) and try to outperform the current one. Define a workflow to apply what we have learned to other aggregate behaviours not yet implemented.
    \item 3rd year: try to bring ML from design time to runtime to gain robustness against environmental changes. Check if we still prove the same theoretical results (e.g. eventual consistency) of "classic" AC with the blocks synthesised by learning.
\end{itemize}
\section*{Acknowledgement}
%% improve
Special thanks to my PhD supervisor Prof. Mirko Viroli
\bibliographystyle{ieeetr}
\bibliography{mybibfile}
\end{document}
