\documentclass[conference]{IEEEtran}
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage[inline]{enumitem}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Towards Field-Based Coordination with Learning}

\author{\IEEEauthorblockN{PhD Student Gianluca Aguzzi}
\IEEEauthorblockA{\textit{University of Bologna} \\
Cesena, Italy \\
gianluca.aguzzi@unibo.it}
\and
\IEEEauthorblockN{Supervisor Mirko Viroli}
\IEEEauthorblockA{\textit{University of Bologna} \\
Cesena, Italy \\
mirko.viroli@unibo.it}
}

\maketitle

\begin{IEEEkeywords}
Field Coordination, Aggregate Computing, Multi-Agent Reinforcement Learning
\end{IEEEkeywords}

\section{Motivation and challenges}
Humans, in the last century, have filled the earth with computational entities. 
%
We find things able to compute in smartphones, fridges, and watches. % improve this period
Nowadays, these devices aren't isolated; rather, they form a hoard of inter-communicating entities capable of achieving collective tasks. 
These systems exhibit properties usually observed in complex such as node acting in concurrent, 
decentralized control and the global behavior emerge from local interactions~\cite{DBLP:conf/huc/Ferscha15}. 
Swarm of UAVs, a crowd of people, smart cities is all instances of these kinds of systems, usually called Collective Adaptive Systems.
%
In literature, different techniques aim at taming this complexity at the engineering level.
Among the many, two solutions that use a top-down approach in expressing global behaviour are TOTA~\cite{DBLP:journals/tosem/MameiZ09} and Aggregate Computing~\cite{DBLP:journals/computer/BealPV15} (both classified under the umbrella of Field-Based Coordination~\cite{DBLP:books/daglib/0015276}).
The latter is a novel approach in which developers can express the collective behavior by
a functional manipulation of a distributed data structure called a computational field.
In bottom-up approaches instead, self-organization is something that emerges, tuning algorithm parameters.
Aggregate programming is backed by field calculus, a minimal set of instructions necessary to express whatever spatiotemporal computation using computational field manipulation~\cite{DBLP:conf/coordination/AudritoBDV18}. 
On top of that, different building blocks have been built, to facilitate the high-level library definition.
Furthermore, crafting a specific blocks category is possible to verify relevant properties such as self-stabilization~\cite{DBLP:conf/coordination/ViroliD14} and eventual consistency~\cite{DBLP:conf/saso/BealVPD16}.
Practically though, building these basic blocks is not as easy as it sounds. 
Moreover, it is difficult to guarantee certain quality levels under different network conditions (e.g., different typologies, high node mobility, etc.)

Outward of top-down declarative approaches, in the context of Multi-Agent Systems, other solutions leverage evolutionary computing~\cite{DBLP:journals/swarm/BrambillaFBD13} and machine learning (in particular Multi-Agent Reinforcement Learning~\cite{DBLP:journals/tcyb/NguyenNN20}) to design distributed programs.
Using these techniques brings near-optimum solutions to specific tasks.
Unfortunately, though, the main problems of those solutions are the difficulty in scaling up application complexity, the reusability of the behavior found in other circumstances, and the "black-box" nature. 
%
Definitely, the Aggregate Computing model is challenging in terms of usual learning problems. Indeed:
\begin{enumerate*}[label=(\roman*)]
\item there isn't any population size guarantee,
\item the neighborhood is potentially highly dynamic,
\item the system behavior is usually evaluated from the macro-level and not from the micro-level, and
\item each node has partial information about the system (in typical Dec-POMDP~\cite{DBLP:conf/uai/BernsteinZI00} settings)
\end{enumerate*}
\section{Contribution and objectives}
As far as we know, these two worlds are disjointed even if they speak a similar language. So our first intuition (and our key objective) was merging these approaches to gain benefits from both worlds creating a declarative, 
composable and self-explanatory behavior combined with online adaptivity and robustness towards environmental changes.
%
This has inevitably led us to ask ourselves these questions that guided us in the preliminary research phases: at what level of abstraction (middleware? Application API? Building blocks?) learning can be useful for Aggregate Computing? 
In related works, exists a well-known approach that easily matches with Aggregate Computing? There are some benefits?
%
\section{Methodology and preliminary results}
%
As the first step, we consider related work in Multi-Agent Systems and Swarm Robotics because, in some cases, problems have similar settings.
To reach our objective, we iteratively 
\begin{enumerate*}[label=(\roman*)]
\item read related works,
\item take inspiration from one of them and craft an initial prototype, and
\item try to generalize the solution from complex problems
\end{enumerate*}
Aggregate Computing currently is supported by different toolkit as ScaFi~\cite{DBLP:conf/ecoop/CasadeiV16} and Protelis~\cite{DBLP:conf/sac/PianiniVB15}, making
our \emph{trial-and-error} process faster. In this first part, we focused on pratical results than fundational one, hiding detalis of engineering 
hybrid systems like these.  

Currently, we applied learning on building blocks; because they have an outstanding effect at the application level but
at the same time, the behaviors expressed are simple, so easily synthesized via learning.  %%improve settings
%
Our test application is the distance gradient from a source zone. 
It is an idiomatic pattern useful for Field-Based calculus for creating different collective behavior ranging from distributed sensing to information diffusion.
Furthermore, it is used to build other complex patterns like Self-organising coordination regions~\cite{DBLP:conf/coordination/CasadeiPVN19}.
%
Naive gradient implementations suffer from slow-rising, so different hand-crafted solutions have been built, such as Flex, BIS, and ULT~\cite{DBLP:conf/saso/AudritoCDV17}.
Our goal is to reach a similar performance of the best hand-crafted solution (the ULT gradient).
%
From related works, we observe a current trend in applying Reinforcement Learning in distributed applications (called Indipedent Learning, because each agent conceptually learns the policy without knowing other agents).
Q-Learning~\cite{DBLP:journals/ras/Krose95}, even if it is born for a single agent and for a stationary enviroment, it is applied in 
different largerly applied scenarios, also with same improvement (e.g. Hysteretic Q-Learning~\cite{DBLP:conf/iros/MatignonLF07} tries to 
manages the non-stationary problem nature). It is worth noting that, no convergence theorem to global optiomal policy exists in Multi Agent settings, we had in some cases
the Nash Equilibra convergence (in particular in Multi Agent Reinforcement Learning).
%
As first attempt, we try to encode our gradient problem in terms of a learning problem and then using Q-Learning (or also the Monte Carlo Learning~\cite{DBLP:conf/nips/Thrun99}).
The experiments done help us to clearly asses the problem in this combination such as. 
The difficult tasks concern: encoding local state giving neighbours values, fina a right reward function that expresses the utility of 
the individual regarding the collective result, encode right actions, highly non-stationary behaviour. 
% todo speak about regression model
In particular, the gradient problems is fairly difficult in encoding in learning task speaking due the continuous state and action space.
So, we also consider to use Neural Network in order to perform regression task, using a Backprograpagion algorithm to 
enhance the model performance. 
Sadly, this method doesn't not scale in complex problem: even with a global system observation, is difficult to know the right result at certain point in time, so 
we cannot give a right baseline for a Backprograpagion algorithms.
%
Finally, observing evolutionary robotics and for avoiding loss function definition, we try some basic evolutionary methods, such as Neuroevolution of Augmenting Topologies Alternatives~\cite{DBLP:journals/ec/StanleyM02}.
The benefinits of evolutionary algorithm is the very limited constraied given. Indeed the encoding is fairly straightforward.
The problems encountered are the slowness and the difficulty in generalization, that is one of our goals.
%
\section{Future work and research plan}
Aggregate Computing needs a platform in which programs will be executed. 
Here, designers need to define aspects that the paradigm doesn't include, 
such as evaluation frequency, program displacement, and trust. 
These themes are tackled in part in different works~\cite{DBLP:journals/scp/CasadeiAV18, DBLP:journals/fi/CasadeiPPVW20, DBLP:journals/corr/abs-2012-13806}, 
but online learning is usually not considered and here could be crucial, 
avoiding complex parameters tuning and improving the system robustness.
Regarding evaluation frequency, related work already applied Reinforcement Learning. 
Indeed, following an ad-hoc crafted reward function, we might bring the system to reduce energy 
consumption even in our solution.

\bibliographystyle{ieeetr}
\bibliography{mybibfile}
\end{document}
